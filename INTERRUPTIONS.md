# Interrupciones (Barge-in) - OpenAI Realtime API

## âœ… Implementado

El asistente ahora soporta **interrupciones naturales** (barge-in): cuando el asistente estÃ¡ hablando y tÃº empiezas a hablar, se detiene inmediatamente para escucharte.

## CÃ³mo funciona

### Flujo de interrupciÃ³n

```
Asistente estÃ¡ hablando (estado: 'speaking')
    â†“
Usuario empieza a hablar
    â†“
OpenAI detecta: input_audio_buffer.speech_started
    â†“
Sistema verifica: Â¿asistente hablando? âœ…
    â†“
1. EnvÃ­a response.cancel a OpenAI
2. Limpia buffer de audio local
3. Cambia estado a 'listening'
    â†“
OpenAI responde: response.cancelled
    â†“
Asistente escucha al usuario
```

## ImplementaciÃ³n

### En `useOpenAIRealtime.ts:270-293`

```typescript
case 'input_audio_buffer.speech_started':
  console.log('ğŸ¤ User speech started');

  // Si el asistente estÃ¡ hablando, interrumpirlo (barge-in)
  if (stateRef.current === 'speaking') {
    console.log('âš ï¸ Interrupting assistant response...');

    // 1. Cancelar la respuesta actual en OpenAI
    if (wsRef.current && wsRef.current.readyState === WebSocket.OPEN) {
      wsRef.current.send(JSON.stringify({
        type: 'response.cancel'
      }));
      console.log('ğŸ“¤ Sent response.cancel to OpenAI');
    }

    // 2. Limpiar el buffer de audio que estÃ¡ reproduciendo
    if (audioPlayerRef.current) {
      audioPlayerRef.current.clear();
      console.log('ğŸ§¹ Cleared audio playback buffer');
    }
  }

  setState('listening');
  break;
```

### Evento de cancelaciÃ³n

```typescript
case 'response.cancelled':
  console.log('ğŸš« Response cancelled (interrupted by user)');
  setState('listening');
  break;
```

## Eventos involucrados

### 1. DetecciÃ³n de voz del usuario
```json
{
  "type": "input_audio_buffer.speech_started"
}
```
- **Enviado por**: OpenAI (server VAD)
- **CuÃ¡ndo**: Detecta que el usuario empezÃ³ a hablar
- **AcciÃ³n**: Verificar si hay que interrumpir

### 2. CancelaciÃ³n de respuesta
```json
{
  "type": "response.cancel"
}
```
- **Enviado por**: Cliente
- **CuÃ¡ndo**: Usuario interrumpe al asistente
- **Resultado**: OpenAI detiene la generaciÃ³n de respuesta

### 3. ConfirmaciÃ³n de cancelaciÃ³n
```json
{
  "type": "response.cancelled"
}
```
- **Enviado por**: OpenAI
- **CuÃ¡ndo**: DespuÃ©s de cancelar exitosamente
- **AcciÃ³n**: Estado vuelve a 'listening'

## Comportamiento esperado

### âœ… Interrupciones exitosas

**Escenario 1: InterrupciÃ³n temprana**
```
Usuario: "Â¿CuÃ¡l es el horario del...?"
Asistente: "El horario del restaurante es deâ€”"
Usuario: "Espera, mejor dime sobre el spa"
Asistente: [SE DETIENE INMEDIATAMENTE]
Asistente: "Claro, el spa estÃ¡ abierto..."
```

**Escenario 2: CorrecciÃ³n**
```
Asistente: "Te puedo ayudar con la reserva para maÃ±ana a lasâ€”"
Usuario: "No, no es para maÃ±ana"
Asistente: [SE DETIENE]
Asistente: "Entendido, Â¿para quÃ© dÃ­a es la reserva?"
```

**Escenario 3: Cambio de tema**
```
Asistente: "El check-out es a las 12 del mediodÃ­a y puedes solicitarâ€”"
Usuario: "Oye, tengo otra pregunta"
Asistente: [SE DETIENE]
Asistente: "Claro, dime"
```

### âŒ Sin interrupciones

El asistente NO se interrumpe cuando:
- El usuario NO estÃ¡ hablando (ruido de fondo no cuenta)
- El asistente NO estÃ¡ hablando (estado â‰  'speaking')
- El WebSocket estÃ¡ desconectado

## Logs en consola

Cuando hay una interrupciÃ³n, verÃ¡s:

```
ğŸ¤ User speech started
âš ï¸ Interrupting assistant response...
ğŸ“¤ Sent response.cancel to OpenAI
ğŸ§¹ Cleared audio playback buffer
ğŸ“¥ Server event: response.cancelled
ğŸš« Response cancelled (interrupted by user)
```

## Ajustes

### Sensibilidad de detecciÃ³n

Si las interrupciones son muy sensibles (se activan con ruido):
```typescript
// En useOpenAIRealtime.ts:123
turn_detection: {
  threshold: 0.6,  // â† Aumentar (menos sensible)
  // ...
}
```

Si las interrupciones son lentas:
```typescript
turn_detection: {
  threshold: 0.4,  // â† Reducir (mÃ¡s sensible)
  // ...
}
```

### Evitar falsos positivos

El sistema ya tiene protecciÃ³n contra falsos positivos:
- Solo interrumpe si `state === 'speaking'`
- Requiere que el server VAD detecte voz real (no ruido)

## Ventajas

âœ… **ConversaciÃ³n natural**: Como hablar con una persona real
âœ… **Respuesta inmediata**: Se detiene al instante
âœ… **Sin desperdicio**: OpenAI deja de generar (ahorra tokens)
âœ… **Audio limpio**: No quedan fragmentos reproduciendo

## Limitaciones conocidas

âš ï¸ **Latencia de red**: ~50-200ms entre hablar y que se detenga
âš ï¸ **Fragmentos cortos**: Audio muy corto puede terminar antes de cancelar
âš ï¸ **Overlapping**: No se puede hablar simultÃ¡neamente (es turn-based)

## PrÃ³ximos pasos

- [ ] Agregar modo de conversaciÃ³n simultÃ¡nea (full-duplex)
- [ ] Implementar "resume" para continuar respuestas interrumpidas
- [ ] AÃ±adir feedback visual cuando se interrumpe
- [ ] MÃ©tricas de interrupciones (cuÃ¡ntas veces, duraciÃ³n, etc.)

## Referencias

- [OpenAI Realtime API - Response Control](https://platform.openai.com/docs/api-reference/realtime-client-events/response/cancel)
- [Server VAD Configuration](https://platform.openai.com/docs/guides/realtime#turn-detection)
